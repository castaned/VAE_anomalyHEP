{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_kg_hide-output": true,
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "papermill": {
     "duration": 14.069112,
     "end_time": "2023-12-08T11:23:24.841190",
     "exception": false,
     "start_time": "2023-12-08T11:23:10.772078",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[rank: 0] Seed set to 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import torch\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "import pandas as pd\n",
    "import lightning as L\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint, ProgressBar\n",
    "from lightning.pytorch.callbacks.early_stopping import EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "np.random.seed(seed=1)\n",
    "L.seed_everything(seed=1, workers=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the list of variables from the h5 file to use as features, spectator and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 27 features\n",
    "features = ['fj_jetNTracks',\n",
    "            'fj_nSV',\n",
    "            'fj_tau0_trackEtaRel_0',\n",
    "            'fj_tau0_trackEtaRel_1',\n",
    "            'fj_tau0_trackEtaRel_2',\n",
    "            'fj_tau1_trackEtaRel_0',\n",
    "            'fj_tau1_trackEtaRel_1',\n",
    "            'fj_tau1_trackEtaRel_2',\n",
    "            'fj_tau_flightDistance2dSig_0',\n",
    "            'fj_tau_flightDistance2dSig_1',\n",
    "            'fj_tau_vertexDeltaR_0',\n",
    "            'fj_tau_vertexEnergyRatio_0',\n",
    "            'fj_tau_vertexEnergyRatio_1',\n",
    "            'fj_tau_vertexMass_0',\n",
    "            'fj_tau_vertexMass_1',\n",
    "            'fj_trackSip2dSigAboveBottom_0',\n",
    "            'fj_trackSip2dSigAboveBottom_1',\n",
    "            'fj_trackSip2dSigAboveCharm_0',\n",
    "            'fj_trackSipdSig_0',\n",
    "            'fj_trackSipdSig_0_0',\n",
    "            'fj_trackSipdSig_0_1',\n",
    "            'fj_trackSipdSig_1',\n",
    "            'fj_trackSipdSig_1_0',\n",
    "            'fj_trackSipdSig_1_1',\n",
    "            'fj_trackSipdSig_2',\n",
    "            'fj_trackSipdSig_3',\n",
    "            'fj_z_ratio']\n",
    "\n",
    "# spectators to define mass/pT window\n",
    "spectators = ['fj_sdmass',\n",
    "              'fj_pt']\n",
    "\n",
    "# 2 labels: QCD or Hbb\n",
    "labels = ['fj_isQCD*sample_isQCD',\n",
    "          'fj_isH*fj_isBB']\n",
    "\n",
    "nfeatures = len(features)\n",
    "nspectators = len(spectators)\n",
    "nlabels = len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features_labels(file_name, remove_mass_pt_window=True):\n",
    "    # load file\n",
    "    h5file = tables.open_file(file_name, 'r')\n",
    "    njets = getattr(h5file.root,features[0]).shape[0]\n",
    "\n",
    "    # allocate arrays\n",
    "    feature_array = np.zeros((njets,nfeatures))\n",
    "    spec_array = np.zeros((njets,nspectators))\n",
    "    label_array = np.zeros((njets,nlabels))\n",
    "\n",
    "    # load feature arrays\n",
    "    for (i, feat) in enumerate(features):\n",
    "        feature_array[:,i] = getattr(h5file.root,feat)[:]\n",
    "\n",
    "    # load spectator arrays\n",
    "    for (i, spec) in enumerate(spectators):\n",
    "        spec_array[:,i] = getattr(h5file.root,spec)[:]\n",
    "\n",
    "    # load labels arrays\n",
    "    for (i, label) in enumerate(labels):\n",
    "        prods = label.split('*')\n",
    "        prod0 = prods[0]\n",
    "        prod1 = prods[1]\n",
    "        fact0 = getattr(h5file.root,prod0)[:]\n",
    "        fact1 = getattr(h5file.root,prod1)[:]\n",
    "        label_array[:,i] = np.multiply(fact0,fact1)\n",
    "\n",
    "    # remove samples outside mass/pT window\n",
    "    if remove_mass_pt_window:\n",
    "        feature_array = feature_array[(spec_array[:,0] > 40) & (spec_array[:,0] < 200) & (spec_array[:,1] > 300) & (spec_array[:,1] < 2000)]\n",
    "        label_array = label_array[(spec_array[:,0] > 40) & (spec_array[:,0] < 200) & (spec_array[:,1] > 300) & (spec_array[:,1] < 2000)]\n",
    "\n",
    "    feature_array = feature_array[np.sum(label_array,axis=1)==1]\n",
    "    label_array = label_array[np.sum(label_array,axis=1)==1]\n",
    "\n",
    "    h5file.close()\n",
    "    return feature_array, label_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy training file if it doesn't exist\n",
    "import os.path\n",
    "if not os.path.isfile('dataset/ntuple_merged_10.h5'): \n",
    "    !xrdcp root://eospublic.cern.ch//eos/opendata/cms/datascience/HiggsToBBNtupleProducerTool/HiggsToBBNTuple_HiggsToBB_QCD_RunII_13TeV_MC/train/ntuple_merged_10.h5 .\n",
    "\n",
    "# load training file\n",
    "feature_array, label_array = get_features_labels('dataset/ntuple_merged_10.h5', remove_mass_pt_window=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 17.        ,   0.        ,  -1.        ,  -1.        ,\n",
       "        -1.        ,  -1.        ,  -1.        ,  -1.        ,\n",
       "        -1.        ,  -1.        ,  -1.        ,  -1.        ,\n",
       "        -1.        ,  -1.        ,  -1.        ,   0.68886769,\n",
       "         0.65574616,   1.37614286,   2.87837458,  -3.39589477,\n",
       "       -50.        ,   2.32891273,   2.87837458,   2.32891273,\n",
       "         1.69894099,   1.56711352,  -3.        ])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_array[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/LUSTRE/home/ccd/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "ae_tdl = DataLoader(feature_array, batch_size=batch_size, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SensorDataset(Dataset):\n",
    "\n",
    "    def __init__(self, dataset: np.array):\n",
    "        self.dataset = dataset\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return torch.FloatTensor(self.dataset[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "ae_train_ds = SensorDataset(feature_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 17.0000,   0.0000,  -1.0000,  -1.0000,  -1.0000,  -1.0000,  -1.0000,\n",
       "         -1.0000,  -1.0000,  -1.0000,  -1.0000,  -1.0000,  -1.0000,  -1.0000,\n",
       "         -1.0000,   0.6889,   0.6557,   1.3761,   2.8784,  -3.3959, -50.0000,\n",
       "          2.3289,   2.8784,   2.3289,   1.6989,   1.5671,  -3.0000])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ae_train_ds[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autoencoder\n",
    "#### AE: Pytorch Lightning Model Implementation\n",
    "Implementation of a plain Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(L.LightningModule):\n",
    "\n",
    "    def __init__(self, in_dim):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(in_dim, 32),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.SELU(),\n",
    "            nn.Linear(32, 16),\n",
    "            nn.BatchNorm1d(16),\n",
    "            nn.SELU(),\n",
    "            nn.Linear(16, 8),\n",
    "        )\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(8, 16),\n",
    "            nn.BatchNorm1d(16),\n",
    "            nn.SELU(),\n",
    "            nn.Linear(16, 32),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.SELU(),\n",
    "            nn.Linear(32, in_dim)\n",
    "        )\n",
    "\n",
    "        self.training_losses = []\n",
    "        self.validation_losses = []\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.encoder(x)\n",
    "        return self.decoder(z)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        input = batch\n",
    "        output = self.forward(input)\n",
    "        loss = F.mse_loss(output, input)\n",
    "        self.log('train_loss', loss, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def on_train_epoch_end(self):\n",
    "        self.training_losses.append(self.trainer.callback_metrics['train_loss'].item())\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        input = batch\n",
    "        output = self.forward(input)\n",
    "        loss = F.mse_loss(output, input)\n",
    "        self.log('val_loss', loss, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        self.validation_losses.append(self.trainer.callback_metrics['val_loss'].item())\n",
    "\n",
    "    def predict_step(self, batch, batch_idx, dataloader_idx=None):\n",
    "        input = batch\n",
    "        output = self.forward(input)\n",
    "        return output\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.AdamW(self.parameters(), lr=1e-3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
